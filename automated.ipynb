{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08976528-740a-4adf-8786-de68c98b7555",
   "metadata": {},
   "source": [
    "## import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff036295-808c-47fc-aa68-d0dbc380862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import random\n",
    "import pyproj\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2821cbdc-e4d5-454d-8597-0fb3c679fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prefix you want to search for\n",
    "prefix = 'R'\n",
    "\n",
    "# Get a list of all variables in the current Jupyter session\n",
    "all_variables = %who_ls\n",
    "\n",
    "# Filter variables that start with the specified prefix\n",
    "filtered_variables = [var for var in all_variables if var.startswith(prefix)]\n",
    "\n",
    "# Print the filtered variables and their values\n",
    "for var in filtered_variables:\n",
    "    print(f\"{var}: {globals()[var]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46f39c5-e3df-408e-a46e-457a72dea414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas shapely pyproj folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec387439-f25a-4784-b8d1-6f58dbea1300",
   "metadata": {},
   "source": [
    "## add some user-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "486e83b1-3047-4df7-a9f6-3daf31cd4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_zeros(df, columns=None):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    return df[~(df[columns] == 0).any(axis=1)]\n",
    "\n",
    "shape = 'city_bound_UTM/Eslamshar_elec_mark.shp'\n",
    "#elec_auth = 'path/to/there'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0566ef-18f4-43c4-88b3-98a11aa0fd21",
   "metadata": {},
   "source": [
    "## I - data pre-filtering by previous phase and split it into two parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a308f7-94f5-471d-b137-776054ec279f",
   "metadata": {},
   "source": [
    "### load access raw dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c06f46-d800-4e4a-8311-4ad414d0797e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_ID</th>\n",
       "      <th>agent_x</th>\n",
       "      <th>agent_y</th>\n",
       "      <th>counter_x</th>\n",
       "      <th>counter_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8256564304224</td>\n",
       "      <td>520572.0</td>\n",
       "      <td>3934172.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8442572304223</td>\n",
       "      <td>520178.0</td>\n",
       "      <td>3931545.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8685393504228</td>\n",
       "      <td>520390.0</td>\n",
       "      <td>3932362.0</td>\n",
       "      <td>520349.0</td>\n",
       "      <td>3932309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8520916604222</td>\n",
       "      <td>520409.0</td>\n",
       "      <td>3932472.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8521526604228</td>\n",
       "      <td>520411.0</td>\n",
       "      <td>3932471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bill_ID   agent_x    agent_y  counter_x  counter_y\n",
       "0  8256564304224  520572.0  3934172.0        NaN        NaN\n",
       "1  8442572304223  520178.0  3931545.0        NaN        NaN\n",
       "2  8685393504228  520390.0  3932362.0   520349.0  3932309.0\n",
       "3  8520916604222  520409.0  3932472.0        NaN        NaN\n",
       "4  8521526604228  520411.0  3932471.0        NaN        NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_column_name = ['bill_ID','agent_x', 'agent_y', 'counter_x', 'counter_y']\n",
    "access_df = pd.read_csv('access_table.txt', delimiter = ',', names=access_column_name)\n",
    "access_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2077fd4-a526-4114-8c77-fe8fd7956c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_ID</th>\n",
       "      <th>agent_x</th>\n",
       "      <th>agent_y</th>\n",
       "      <th>counter_x</th>\n",
       "      <th>counter_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4273985</th>\n",
       "      <td>8632699404220</td>\n",
       "      <td>521586.0</td>\n",
       "      <td>3931862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273986</th>\n",
       "      <td>8632699404220</td>\n",
       "      <td>521588.0</td>\n",
       "      <td>3931862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273987</th>\n",
       "      <td>8632699404220</td>\n",
       "      <td>521587.0</td>\n",
       "      <td>3931863.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273988</th>\n",
       "      <td>8632699404220</td>\n",
       "      <td>521588.0</td>\n",
       "      <td>3931867.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273989</th>\n",
       "      <td>8632699404220</td>\n",
       "      <td>521591.0</td>\n",
       "      <td>3931864.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bill_ID   agent_x    agent_y  counter_x  counter_y\n",
       "4273985  8632699404220  521586.0  3931862.0        NaN        NaN\n",
       "4273986  8632699404220  521588.0  3931862.0        NaN        NaN\n",
       "4273987  8632699404220  521587.0  3931863.0        NaN        NaN\n",
       "4273988  8632699404220  521588.0  3931867.0        NaN        NaN\n",
       "4273989  8632699404220  521591.0  3931864.0        NaN        NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "access_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113430b2-8d68-4127-936c-1d0eca14644c",
   "metadata": {},
   "source": [
    "### extract table dimention for further reporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5773be-7595-4836-929e-3dfc7a6c5142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 4273989\n",
      "Number of unique IDs: 189875\n"
     ]
    }
   ],
   "source": [
    "R_access_rows = (access_df.shape[0]) -1 \n",
    "R_access_ID_unique = len(access_df['bill_ID'].unique())\n",
    "# Display the number of rows\n",
    "print(\"Number of records:\", R_access_rows)\n",
    "print(\"Number of unique IDs:\", R_access_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e770de41-2f51-4a07-ad93-b38b09058999",
   "metadata": {},
   "source": [
    "### load the DBSCAN block_accu for filtering prevous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dcaf4ea-0ce8-4912-90cc-c56d054b1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_df = pd.read_csv('dbscan.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219e7e1a-60bb-499d-a29a-47bea523cd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILL_IDENT</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8717022804228</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8259334804227</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8494666504226</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8385632004220</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8492681804225</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BILL_IDENT  NUM\n",
       "0  8717022804228   15\n",
       "1  8259334804227   15\n",
       "2  8494666504226   15\n",
       "3  8385632004220   15\n",
       "4  8492681804225   15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd4a6d37-984e-4967-a26a-718e1346f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BILL_IDENT</th>\n",
       "      <th>NUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134578</th>\n",
       "      <td>8699301304229</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134579</th>\n",
       "      <td>8256793904227</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134580</th>\n",
       "      <td>8255283504228</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134581</th>\n",
       "      <td>8746657504220</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134582</th>\n",
       "      <td>8499709304228</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BILL_IDENT  NUM\n",
       "134578  8699301304229   16\n",
       "134579  8256793904227   15\n",
       "134580  8255283504228   15\n",
       "134581  8746657504220    7\n",
       "134582  8499709304228   13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41728fab-835a-44b0-90c5-4446f5eb4f34",
   "metadata": {},
   "source": [
    "### extract table dimention for further reporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b98325b0-2a92-4390-8fd5-cad7b17351cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records and Unique IDs: 134582\n"
     ]
    }
   ],
   "source": [
    "R_dbscan_rows_uniqueID = (dbscan_df.shape[0]) - 1\n",
    "print(\"Number of records and Unique IDs:\", R_dbscan_rows_uniqueID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592c96e-5e16-425c-8fc4-de1217427a97",
   "metadata": {},
   "source": [
    "### colloct unique bill_IDs form DBSCAN data ( the IDs are unique but we do it to make sure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352c13ff-e8d9-4637-aa4c-abc404e5e81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_ID_unique = access_df['bill_ID'].unique()\n",
    "bill_ident_value = dbscan_df['BILL_IDENT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba9e342-c9a4-453a-866a-146931c0358d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8717022804228 8259334804227 8494666504226 ... 8255283504228 8746657504220\n",
      " 8499709304228]\n"
     ]
    }
   ],
   "source": [
    "print(bill_ident_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9705d98-70e4-4170-a009-9194f48d1c0d",
   "metadata": {},
   "source": [
    "### remove common IDs from data table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a26a549-7a4a-4b85-acec-16e32ce6549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_by_dbscan_df =access_df[~access_df['bill_ID'].isin(bill_ident_value)]\n",
    "#access_bill_id_filterd_value = filter_access_df['bill_ID'].unique()\n",
    "flt_by_dbscan_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3983cd9-0962-402d-a6a8-a5737d7f8d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_ID</th>\n",
       "      <th>agent_x</th>\n",
       "      <th>agent_y</th>\n",
       "      <th>counter_x</th>\n",
       "      <th>counter_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1111862</th>\n",
       "      <td>8613350104225</td>\n",
       "      <td>526675.0</td>\n",
       "      <td>3933960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111863</th>\n",
       "      <td>8613350104225</td>\n",
       "      <td>527572.0</td>\n",
       "      <td>3931762.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111864</th>\n",
       "      <td>8613350104225</td>\n",
       "      <td>526662.0</td>\n",
       "      <td>3934166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111865</th>\n",
       "      <td>8613350104225</td>\n",
       "      <td>526663.0</td>\n",
       "      <td>3933935.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111866</th>\n",
       "      <td>8613350104225</td>\n",
       "      <td>526667.0</td>\n",
       "      <td>3933964.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bill_ID   agent_x    agent_y  counter_x  counter_y\n",
       "1111862  8613350104225  526675.0  3933960.0        NaN        NaN\n",
       "1111863  8613350104225  527572.0  3931762.0        NaN        NaN\n",
       "1111864  8613350104225  526662.0  3934166.0        NaN        NaN\n",
       "1111865  8613350104225  526663.0  3933935.0        NaN        NaN\n",
       "1111866  8613350104225  526667.0  3933964.0        NaN        NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flt_by_dbscan_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9ffd5-65aa-4407-aa40-38376508f1fb",
   "metadata": {},
   "source": [
    "### extract table dimention for further reporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "118fd3c4-1fbc-46c3-baa3-98c9d404321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 1111867\n",
      "Number of unique IDs: 55640\n"
     ]
    }
   ],
   "source": [
    "R_flt_by_dbscan_rows = flt_by_dbscan_df.shape[0]\n",
    "R_flt_by_dbscan_ID_unique = len(flt_by_dbscan_df['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_flt_by_dbscan_rows)\n",
    "print(\"Number of unique IDs:\", R_flt_by_dbscan_ID_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab6af212-3b77-4e46-bcca-f85734b4a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_by_dbscan_df.to_csv('filtered_by_dbscan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87bba1b-cc22-46d0-8dc9-84d9eb4b01d0",
   "metadata": {},
   "source": [
    "### replace zeros in agent with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "189a0a62-8b85-4b74-9e07-47720ee84722",
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_by_dbscan_df.replace(0, np.nan, inplace=True)\n",
    "flt_by_dbscan_df.to_csv('filtered_by_dbscan_zer2null.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06255cf-5d92-475f-ab26-762234616430",
   "metadata": {},
   "source": [
    "###  split data into two part ( agent base or counter base ) extract IDs with counter X,Y ( they may have agent X,Y as well)\n",
    "### create two CSVs file that are included or excluded rows with counter coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86576d91-0e69-4587-ab1b-0b92b286ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rows with non-null values for counter_x and counter_y\n",
    "counter_data_df = flt_by_dbscan_df.dropna(subset=['counter_x', 'counter_y'])\n",
    "counter_data_df.to_csv('counter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4918c2e5-bb02-464c-85c0-0531dcb09117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 252781\n",
      "Number of unique IDs: 17150\n"
     ]
    }
   ],
   "source": [
    "R_counter_data_rows = counter_data_df.shape[0]\n",
    "R_counter_data_ID_unique = len(counter_data_df['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_counter_data_rows)\n",
    "print(\"Number of unique IDs:\", R_counter_data_ID_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10654421-ae75-41fd-ae5b-2cdbe83e5a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where counter_x and counter_y are NaN\n",
    "agent_data_df = flt_by_dbscan_df[pd.isnull(flt_by_dbscan_df['counter_x']) & pd.isnull(flt_by_dbscan_df['counter_y'])]\n",
    "\n",
    "# Save the  DataFrame if needed\n",
    "agent_data_df.to_csv('agent_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf3bdb9e-4ae0-45ad-b5ff-8101a524f9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 857326\n",
      "Number of unique IDs: 38399\n"
     ]
    }
   ],
   "source": [
    "R_agent_data_df_rows = agent_data_df.shape[0]\n",
    "R_agent_data_ID_unique = len(agent_data_df['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_agent_data_df_rows)\n",
    "print(\"Number of unique IDs:\", R_agent_data_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcfdf0a-7b24-493f-bacb-ac00c9561e8a",
   "metadata": {},
   "source": [
    "## II - Process table contains counter coordinates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f78c8-9a80-406d-a764-1a09ddb5350e",
   "metadata": {},
   "source": [
    "### display counters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09721b67-2799-4dd6-865b-db5654f26a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtered CSV data\n",
    "data = pd.read_csv('counter_data.csv')\n",
    "df = data.drop_duplicates(subset='bill_ID')\n",
    "# Sample a subset of the data\n",
    "sampled_data = df#.sample(n=16000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['counter_x'].values, sampled_data['counter_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape) ###change the name and path as needed\n",
    "\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()],zoom_start=3.5) #,zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d96e69e4-2dc5-4a9e-9e72-4d38e4d12f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2be8e6-6cc1-4146-b303-7fff94b88831",
   "metadata": {},
   "source": [
    "### fix counter errors, since the oprator mistakenly entered the coordinates inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22080bb5-6f20-4b49-9f80-f5b7d0e22fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with inverted coordinates: 86315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv('counter_data.csv')\n",
    "\n",
    "# Define the mask to identify rows where counter_x and counter_y might be reversed\n",
    "# Typically, UTM x-coordinates are between 100,000 and 900,000 (for zone-specific cases)\n",
    "# y-coordinates range between 0 and 10,000,000\n",
    "mask = (df['counter_x'] > 900000) & (df['counter_y'] < 1000000)\n",
    "\n",
    "# Count the number of rows with inverted coordinates\n",
    "counters_inverted = mask.sum()\n",
    "\n",
    "# Swap the counter_x and counter_y values where the mask is True\n",
    "df.loc[mask, ['counter_x', 'counter_y']] = df.loc[mask, ['counter_y', 'counter_x']].values\n",
    "\n",
    "# Display the count of corrected rows\n",
    "print(f'Number of rows with inverted coordinates: {counters_inverted}')\n",
    "\n",
    "# Optionally, save the corrected DataFrame back to a CSV file\n",
    "df.to_csv('corrected_counter_data.csv', index=False)\n",
    "# save the only rows that has been correceted\n",
    "corrected_rows = df[mask]\n",
    "corrected_rows.to_csv('Jst_fixed_counter_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf177c-b54f-44db-99ab-049e95fd7cfe",
   "metadata": {},
   "source": [
    "### extract table dimention for further reporting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b07a7ce-b0f3-47ca-b74b-bf38359de778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 86315\n",
      "Number of unique IDs: 9994\n"
     ]
    }
   ],
   "source": [
    "R_fixed_invert_counter_records = corrected_rows.shape[0]\n",
    "R_fixed_invert_counter_ID_unique = len(corrected_rows['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_fixed_invert_counter_records)\n",
    "print(\"Number of unique IDs:\", R_fixed_invert_counter_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e926e1-c5b6-4f01-9c93-62a58d5052ea",
   "metadata": {},
   "source": [
    "### display corrected counters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec2ec27d-d622-48e6-84f8-5c0d8b484697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtered CSV data\n",
    "data = pd.read_csv('corrected_counter_data.csv')\n",
    "df = data.drop_duplicates(subset='bill_ID')\n",
    "# Sample a subset of the data\n",
    "sampled_data = df#.sample(n=16000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['counter_x'].values, sampled_data['counter_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape) ###change the name and path as needed\n",
    "\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()],zoom_start=3.5) #,zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64247425-c7dd-4287-8b6f-ec8081af0d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb310a32-c146-490f-9bf0-9575bdda1830",
   "metadata": {},
   "source": [
    "### remove counter coordiantes from each row since they are outsider ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d669cf98-8b42-4cf6-bd35-13d7ab7b3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              bill_ID   agent_x    agent_y  counter_x  counter_y\n",
      "0       8693290904220  521722.0  3936717.0   521717.0  3936724.0\n",
      "1       8738020704223  521457.0  3936857.0   521474.0  3936848.0\n",
      "2       8691350404220  520574.0  3934585.0   520632.0  3934760.0\n",
      "3       8659094804222  520574.0  3934585.0   520589.0  3934621.0\n",
      "4       8697350304223  520574.0  3934585.0    52092.0  3934531.0\n",
      "...               ...       ...        ...        ...        ...\n",
      "252776  8685114004229  520756.0  3933283.0   520761.0  3933300.0\n",
      "252777  8685114004229  520749.0  3933295.0   520761.0  3933300.0\n",
      "252778  8712756904220  519622.0  3937088.0   519635.0  3937080.0\n",
      "252779  8712756904220  519652.0  3937079.0   519635.0  3937080.0\n",
      "252780  8712756904220  519460.0  3937206.0   519635.0  3937080.0\n",
      "\n",
      "[252781 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_corr = pd.read_csv('corrected_counter_data.csv')\n",
    "\n",
    "# Displaying the first few rows of the DataFrame to ensure it loaded correctly\n",
    "print(df_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03f80ef2-3f6f-46f8-83f5-8eb4d6da7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the shapefile\n",
    "shapefile = gpd.read_file(shape)\n",
    "\n",
    "# Define a function to check if a point is within the shapefile boundary\n",
    "def is_within_boundary(point):\n",
    "    point_geom = Point(point['counter_x'], point['counter_y'])\n",
    "    return shapefile.geometry.contains(point_geom).any()\n",
    "\n",
    "# Filter the DataFrame based on the condition and split into two DataFrames\n",
    "inside_boundary = df[df.apply(is_within_boundary, axis=1)]\n",
    "outside_boundary = df[~df.apply(is_within_boundary, axis=1)]\n",
    "\n",
    "# Reset the index of the DataFrames\n",
    "inside_boundary.reset_index(drop=True, inplace=True)\n",
    "outside_boundary.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the filtered DataFrames to separate files\n",
    "inside_boundary.to_csv('counters_inside_boundary.csv', index=False)\n",
    "outside_boundary.to_csv('counters_outside_boundary.csv', index=False)\n",
    "\n",
    "# Now, inside_boundary contains rows where the counter_x and counter_y values are within the shapefile boundary, \n",
    "# and outside_boundary contains rows where they are outside the boundary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84fecd1-bec4-4d4b-8203-50da84445996",
   "metadata": {},
   "source": [
    "### Inside the city report : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a793941-31ad-4921-b674-61bbbe46822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 16581\n",
      "Number of unique IDs: 16581\n"
     ]
    }
   ],
   "source": [
    "inside_boundary_records = inside_boundary.shape[0]\n",
    "inside_boundary_ID_unique = len(inside_boundary['bill_ID'].unique())\n",
    "print(\"Number of records:\", inside_boundary_records)\n",
    "print(\"Number of unique IDs:\", inside_boundary_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0f62b-da26-4891-843a-51c008bb306a",
   "metadata": {},
   "source": [
    "### outside the city report : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3236318b-d055-4933-91a9-76428a554380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 569\n",
      "Number of unique IDs: 569\n"
     ]
    }
   ],
   "source": [
    "outside_boundary_records = outside_boundary.shape[0]\n",
    "outside_boundary_ID_unique = len(outside_boundary['bill_ID'].unique())\n",
    "print(\"Number of records:\", outside_boundary_records)\n",
    "print(\"Number of unique IDs:\", outside_boundary_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca41bcf-3d45-43a6-b027-9743872a5e27",
   "metadata": {},
   "source": [
    "### outside the city on map :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "629fc252-6055-4844-8630-0f2da94c3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtered CSV data\n",
    "data = pd.read_csv('outside_boundary.csv')\n",
    "df = data.drop_duplicates(subset='bill_ID')\n",
    "# Sample a subset of the data\n",
    "sampled_data = df#.sample(n=16000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['counter_x'].values, sampled_data['counter_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape) ###change the name and path as needed\n",
    "\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()],zoom_start=3.5) #,zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de87d4e9-9906-4038-9218-21008e493b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21e004-682e-4789-b367-bda6cd5a990f",
   "metadata": {},
   "source": [
    "### inside the city on map :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64ddef07-2b2e-46a8-85db-6068c832c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtered CSV data\n",
    "data = pd.read_csv('inside_boundary.csv')\n",
    "df = data.drop_duplicates(subset='bill_ID')\n",
    "# Sample a subset of the data\n",
    "sampled_data = df#.sample(n=16000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['counter_x'].values, sampled_data['counter_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape) ###change the name and path as needed\n",
    "\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()],zoom_start=3.5) #,zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f69f1323-aaa6-4b95-8270-7d1514e0bed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712cb77-05dd-45ce-98c2-5e91e35b6c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8d515-2a71-4c10-beb4-40461efbef6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3831c82-1b71-4964-aa2e-5bae198b7c7a",
   "metadata": {},
   "source": [
    "## III - Process table contains only agents without counter coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b35b48-3f32-476f-9555-b48d49a08048",
   "metadata": {},
   "source": [
    "### load table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af55bedb-45e1-4ac7-9c35-4fb117c90ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_table = pd.read_csv('agent_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2579c35c-52a6-418c-bd1f-be0f7213474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 857326\n",
      "Number of unique IDs: 38399\n"
     ]
    }
   ],
   "source": [
    "R_agent_records = agent_table.shape[0]\n",
    "R_agent_records_ID_unique = len(agent_table['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_agent_records)\n",
    "print(\"Number of unique IDs:\", R_agent_records_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28152142-a650-4265-8d95-124a5ab84391",
   "metadata": {},
   "source": [
    "### ploting data that is Null values and common IDs are removed and area is defined as shapefile :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b7e427a-d8b0-4336-b3f7-4dcce2ef0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample a subset of the data\n",
    "sampled_data = agent_table.sample(n=25000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['agent_x'].values, sampled_data['agent_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape)\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()], zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d049324-fa0b-43be-926d-c35bc28196c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f336c10-6b0d-4642-9840-f94271e345b7",
   "metadata": {},
   "source": [
    "### removing outlayer data by a given shapefile and save it, then plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed684014-845a-41f4-853b-a981f88afbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the CSV file into a pandas DataFrame\n",
    "csv_data = pd.read_csv('agent_data.csv')\n",
    "\n",
    "# Step 2: Convert the DataFrame into a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(csv_data['agent_x'], csv_data['agent_y'])]\n",
    "csv_geo_df = gpd.GeoDataFrame(csv_data, crs=\"EPSG:32639\", geometry=geometry)\n",
    "\n",
    "# Step 3: Read the shapefile into a GeoDataFrame\n",
    "shapefile = gpd.read_file(shape)\n",
    "# Step 4: Perform a spatial join\n",
    "joined_data = gpd.sjoin(csv_geo_df, shapefile, how=\"inner\", op=\"within\")\n",
    "\n",
    "# Step 5: Filter the CSV GeoDataFrame based on the spatial join result\n",
    "agent_data_crpd = csv_geo_df[csv_geo_df.index.isin(joined_data.index)]\n",
    "\n",
    "# Step 6: Save the filtered DataFrame back to a CSV file\n",
    "agent_data_crpd.to_csv('agent_data_crpd.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48014ca8-8b6b-438c-bb1a-17fc7415a1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 850674\n",
      "Number of unique IDs: 38345\n"
     ]
    }
   ],
   "source": [
    "R_agent_inside_boundary_records = agent_data_crpd.shape[0]\n",
    "R_agent_inside_boundary_ID_unique = len(agent_data_crpd['bill_ID'].unique())\n",
    "print(\"Number of records:\", R_agent_inside_boundary_records)\n",
    "print(\"Number of unique IDs:\", R_agent_inside_boundary_ID_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d90ecb-5ec8-43cd-ae7b-28785b2c0cea",
   "metadata": {},
   "source": [
    "### plot a small sample of croped agent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbf64b8f-468e-4e69-88e6-05fd44cb2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the filtered CSV data\n",
    "data = pd.read_csv('agent_data_crpd.csv')\n",
    "\n",
    "# Sample a subset of the data\n",
    "sampled_data = data.sample(n=50000)  # Adjust the number of samples as needed\n",
    "\n",
    "# Convert UTM coordinates to latitude and longitude\n",
    "utm_proj = pyproj.Proj(proj='utm', zone=39, ellps='WGS84')\n",
    "lonlat_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "sampled_data['lon'], sampled_data['lat'] = pyproj.transform(utm_proj, lonlat_proj, sampled_data['agent_x'].values, sampled_data['agent_y'].values)\n",
    "\n",
    "# Read the boundary shapefile\n",
    "boundary_shapefile = gpd.read_file(shape)\n",
    "\n",
    "# Create a Folium map centered at the mean of all points\n",
    "m = folium.Map(location=[sampled_data['lat'].mean(), sampled_data['lon'].mean()], zoom_start=10)\n",
    "\n",
    "# Plot the boundary shapefile\n",
    "folium.GeoJson(boundary_shapefile).add_to(m)\n",
    "\n",
    "# Create a MarkerCluster layer for the sampled data points\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Add markers for each point in the sampled data\n",
    "for idx, row in sampled_data.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['lon']]).add_to(marker_cluster)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8637a0b6-8f5a-4a10-8da0-56590589802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the map\n",
    "#m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ef69bae-b793-4289-8ccd-a3353e9c3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Assuming 'filtered' is your DataFrame\n",
    "data = pd.read_csv('agent_data_crpd.csv')\n",
    "# Grouping by bill_ID and aggregating agent_x and agent_y into lists of tuples\n",
    "grouped_data = data.groupby('bill_ID').apply(lambda x: x[['agent_x', 'agent_y']].values.tolist()).to_dict()\n",
    "\n",
    "# Converting the dictionary to a JSON string\n",
    "json_result = json.dumps(grouped_data, indent=4)\n",
    "\n",
    "# Display the JSON result\n",
    "#print(json_result)\n",
    "\n",
    "# Optionally, save the JSON string to a file\n",
    "with open('result.json', 'w') as file:\n",
    "    file.write(json_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b2162a1-a6d5-408a-8ff9-2c09b03e6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by bill_ID and aggregating agent_x and agent_y into lists\n",
    "data = pd.read_csv('agent_data_crpd.csv')\n",
    "grouped = data.groupby('bill_ID').agg({\n",
    "    'agent_x': list,\n",
    "    'agent_y': list\n",
    "})\n",
    "\n",
    "# Calculating the standard deviation for agent_x and agent_y for each group\n",
    "grouped['agent_x_std'] = data.groupby('bill_ID')['agent_x'].std()\n",
    "grouped['agent_y_std'] = data.groupby('bill_ID')['agent_y'].std()\n",
    "\n",
    "# Calculating the combined standard deviation\n",
    "grouped['MD_agent_std'] = np.sqrt(grouped['agent_x_std']**2 + grouped['agent_y_std']**2)\n",
    "\n",
    "# Calculating the average agent_x and agent_y values for each group\n",
    "grouped['agent_x_avg'] = data.groupby('bill_ID')['agent_x'].mean()\n",
    "grouped['agent_y_avg'] = data.groupby('bill_ID')['agent_y'].mean()\n",
    "\n",
    "# Creating a dictionary from the grouped data\n",
    "grouped_data = grouped.apply(lambda row: {\n",
    "    'agent_x': row['agent_x'],\n",
    "    'agent_y': row['agent_y'],\n",
    "    'agent_x_std': row['agent_x_std'],\n",
    "    'agent_y_std': row['agent_y_std'],\n",
    "    'MD_agent_std': row['MD_agent_std'],\n",
    "    'agent_x_avg': row['agent_x_avg'],\n",
    "    'agent_y_avg': row['agent_y_avg']\n",
    "}, axis=1).to_dict()\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "json_result = json.dumps(grouped_data, indent=4)\n",
    "\n",
    "# Display the JSON result\n",
    "#print(json_result)\n",
    "\n",
    "# Optionally, save the JSON string to a file\n",
    "with open('tst.json', 'w') as file:\n",
    "    file.write(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed0d068a-332d-4ec1-89c6-42bb168b22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "with open('tst.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize the reorganized data dictionary\n",
    "reorganized_data = {}\n",
    "\n",
    "# Reorganize the data\n",
    "for bill_id, info in data.items():\n",
    "    agent_x = info['agent_x']\n",
    "    agent_y = info['agent_y']\n",
    "    \n",
    "    # Combine agent_x and agent_y into coordinate pairs\n",
    "    agent_coordinates = list(zip(agent_x, agent_y))\n",
    "    \n",
    "    # Store the reorganized data\n",
    "    reorganized_data[bill_id] = {\n",
    "        \"agent_coordinates\": agent_coordinates,\n",
    "        \"agent_x_std\": info[\"agent_x_std\"],\n",
    "        \"agent_y_std\": info[\"agent_y_std\"],\n",
    "        \"MD_agent_std\": info[\"MD_agent_std\"],\n",
    "        \"agent_x_avg\": info[\"agent_x_avg\"],\n",
    "        \"agent_y_avg\": info[\"agent_y_avg\"]\n",
    "    }\n",
    "\n",
    "# Convert the reorganized data dictionary to JSON\n",
    "json_result = json.dumps(reorganized_data, indent=4)\n",
    "\n",
    "# Display the JSON result\n",
    "with open('reorg.json', 'w') as file:\n",
    "    file.write(json_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3982cf5-6797-4f66-b1ac-19de8c27775e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
